{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuiladev/Bai4/blob/master/Lab_5_21130645_%C4%90%E1%BA%B7ng_V%C4%83n_Trung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 08/04/2024**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5JsNZAUsdI4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Lab_5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "%pylab inline\n",
        "#%run Utils.ipynb\n",
        "# Warnings configuration\n",
        "# ==============================================================================\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFzf95vME3OD"
      },
      "outputs": [],
      "source": [
        "def apply_svm(X_train, X_test, y_train, y_test, kernel='linear'):\n",
        "    clf = svm.SVC(kernel=kernel)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f'SVM ({kernel} kernel) Metrics:')\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "    return y_pred\n",
        "\n",
        "def apply_logistic_regression(X_train, X_test, y_train, y_test):\n",
        "    clf = LogisticRegression(max_iter=10000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print('Logistic Regression Metrics:')\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "    return y_pred\n",
        "\n",
        "def apply_decision_tree(X_train, X_test, y_train, y_test):\n",
        "    clf = DecisionTreeClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print('Decision Tree Metrics:')\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "    return y_pred\n",
        "\n",
        "def apply_knn(X_train, X_test, y_train, y_test, n_neighbors=5):\n",
        "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f'KNN (n_neighbors={n_neighbors}) Metrics:')\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 1.\n",
        "For **breast cancer** dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply **SVM algorithm** to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (**Logistic Regression, Decision Tree, kNN**) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsg77IBzEyo",
        "outputId": "3fc4d8f0-877a-46e5-8e28-a92459261183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1.1: Apply SVM algorithm with linear kernel\n",
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "Task 1.2: Compare with other competitive algorithms\n",
            "Logistic Regression Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Decision Tree Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        43\n",
            "           1       0.96      0.96      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "KNN (n_neighbors=5) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94        43\n",
            "           1       0.93      1.00      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.94      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "\n",
        "X = cancer.data  # feature matrix\n",
        "y = cancer.target  # target vector\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Task 1.1: Apply SVM algorithm with linear kernel\")\n",
        "y_pred_svm_linear = apply_svm(X_train, X_test, y_train, y_test, kernel='linear')\n",
        "\n",
        "print(\"\\nTask 1.2: Compare with other competitive algorithms\")\n",
        "\n",
        "y_pred_log_reg = apply_logistic_regression(X_train, X_test, y_train, y_test)\n",
        "\n",
        "y_pred_dt = apply_decision_tree(X_train, X_test, y_train, y_test)\n",
        "\n",
        "y_pred_knn = apply_knn(X_train, X_test, y_train, y_test, n_neighbors=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S43IoUT-0OQq"
      },
      "source": [
        "#Task 2.\n",
        "\n",
        "*   2.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   2.2.\tCompare the obtained results in task 2.1 with **SVM** using other kernels (**Polynomial Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: **accuracy, precision, recall, f1** measures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8d463d-a13a-46a7-ec72-d8b0abeae242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "SVM (poly kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.90      1.00      0.95         9\n",
            "           2       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "SVM (sigmoid kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.88      0.78      0.82         9\n",
            "           2       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.90        30\n",
            "   macro avg       0.90      0.90      0.90        30\n",
            "weighted avg       0.90      0.90      0.90        30\n",
            "\n",
            "SVM (rbf kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_pred_svm_linear = apply_svm(X_train, X_test, y_train, y_test, kernel='linear')\n",
        "y_pred_svm_poly = apply_svm(X_train, X_test, y_train, y_test, kernel='poly')\n",
        "y_pred_svm_sigmoid = apply_svm(X_train, X_test, y_train, y_test, kernel='sigmoid')\n",
        "y_pred_svm_rbf = apply_svm(X_train, X_test, y_train, y_test, kernel='rbf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52OPWPD2afi"
      },
      "source": [
        "#Task 3.\n",
        "Compare the performance of selected classification algorithms (**Decision Tree, kNN, Logistic Regression**) and **SVM** (using different kernels) with **FASHION** dataset based on **accuracy, precision, recall, f1** measures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE3ZAbYNH34p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833fbda0-421d-46d0-a92a-9471e62e5ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3: Compare performance of classification algorithms on Fashion-MNIST dataset\n",
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.86      0.76        91\n",
            "           1       0.97      0.93      0.95        92\n",
            "           2       0.60      0.84      0.70        91\n",
            "           3       0.88      0.78      0.83       105\n",
            "           4       0.75      0.61      0.67        99\n",
            "           5       0.89      0.89      0.89       105\n",
            "           6       0.60      0.51      0.55        99\n",
            "           7       0.87      0.87      0.87        94\n",
            "           8       0.96      0.90      0.93       115\n",
            "           9       0.90      0.90      0.90       109\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.82      0.81      0.81      1000\n",
            "\n",
            "SVM (rbf kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.87      0.78        91\n",
            "           1       0.99      0.93      0.96        92\n",
            "           2       0.71      0.79      0.75        91\n",
            "           3       0.84      0.84      0.84       105\n",
            "           4       0.74      0.69      0.71        99\n",
            "           5       0.86      0.86      0.86       105\n",
            "           6       0.52      0.43      0.48        99\n",
            "           7       0.85      0.84      0.84        94\n",
            "           8       0.96      0.93      0.95       115\n",
            "           9       0.88      0.92      0.90       109\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.81      0.81      0.81      1000\n",
            "\n",
            "Logistic Regression Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.82      0.77        91\n",
            "           1       0.95      0.96      0.95        92\n",
            "           2       0.59      0.71      0.65        91\n",
            "           3       0.88      0.77      0.82       105\n",
            "           4       0.66      0.66      0.66        99\n",
            "           5       0.88      0.78      0.83       105\n",
            "           6       0.51      0.43      0.47        99\n",
            "           7       0.83      0.88      0.86        94\n",
            "           8       0.93      0.93      0.93       115\n",
            "           9       0.86      0.86      0.86       109\n",
            "\n",
            "    accuracy                           0.78      1000\n",
            "   macro avg       0.78      0.78      0.78      1000\n",
            "weighted avg       0.79      0.78      0.78      1000\n",
            "\n",
            "Decision Tree Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.64      0.64        91\n",
            "           1       0.88      0.90      0.89        92\n",
            "           2       0.48      0.60      0.54        91\n",
            "           3       0.68      0.66      0.67       105\n",
            "           4       0.56      0.42      0.48        99\n",
            "           5       0.69      0.63      0.66       105\n",
            "           6       0.34      0.35      0.34        99\n",
            "           7       0.76      0.74      0.75        94\n",
            "           8       0.78      0.82      0.80       115\n",
            "           9       0.75      0.78      0.76       109\n",
            "\n",
            "    accuracy                           0.66      1000\n",
            "   macro avg       0.66      0.65      0.65      1000\n",
            "weighted avg       0.66      0.66      0.66      1000\n",
            "\n",
            "KNN (n_neighbors=5) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.85      0.72        91\n",
            "           1       0.99      0.95      0.97        92\n",
            "           2       0.52      0.81      0.64        91\n",
            "           3       0.90      0.77      0.83       105\n",
            "           4       0.71      0.53      0.60        99\n",
            "           5       0.96      0.64      0.77       105\n",
            "           6       0.51      0.40      0.45        99\n",
            "           7       0.72      0.90      0.80        94\n",
            "           8       0.99      0.84      0.91       115\n",
            "           9       0.84      0.93      0.88       109\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.78      0.76      0.76      1000\n",
            "weighted avg       0.78      0.76      0.76      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('data/fashion_train.csv')\n",
        "X_train = train_data.drop('y', axis=1).values\n",
        "y_train = train_data['y'].values\n",
        "\n",
        "test_data = pd.read_csv('data/fashion_test.csv')\n",
        "X_test = test_data.drop('y', axis=1).values\n",
        "y_test = test_data['y'].values\n",
        "\n",
        "print(\"Task 3: Compare performance of classification algorithms on Fashion-MNIST dataset\")\n",
        "\n",
        "y_pred_svm_linear = apply_svm(X_train, X_test, y_train, y_test, kernel='linear')\n",
        "y_pred_svm_rbf = apply_svm(X_train, X_test, y_train, y_test, kernel='rbf')\n",
        "y_pred_log_reg = apply_logistic_regression(X_train, X_test, y_train, y_test)\n",
        "y_pred_dt = apply_decision_tree(X_train, X_test, y_train, y_test)\n",
        "y_pred_knn = apply_knn(X_train, X_test, y_train, y_test, n_neighbors=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      },
      "source": [
        "#Task 4.\n",
        "For a given mobile price classification dataset with the following information:\n",
        "\n",
        "*   **Attributes**: 'battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',     'touch_screen', 'wifi'\n",
        "*   **class label**: ***price_range*** (0,1,2,3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I348UU6nHjGl"
      },
      "source": [
        "#Task 4.1.\n",
        "Compare the performance of selected classification algorithms (**Decision Tree, kNN, Logistic Regression**) and **SVM** (using different kernels) with **mobile price classification** based on **accuracy, precision, recall, f1** measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw_-8FIf2KxW",
        "outputId": "90da0d76-be70-46bd-b3cf-e5fec788c81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90       105\n",
            "           1       0.76      0.86      0.80        91\n",
            "           2       0.79      0.72      0.75        92\n",
            "           3       0.87      0.89      0.88       112\n",
            "\n",
            "    accuracy                           0.84       400\n",
            "   macro avg       0.84      0.83      0.83       400\n",
            "weighted avg       0.84      0.84      0.84       400\n",
            "\n",
            "KNN (n_neighbors=5) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       105\n",
            "           1       0.92      0.93      0.93        91\n",
            "           2       0.89      0.91      0.90        92\n",
            "           3       0.97      0.94      0.95       112\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.94      0.94      0.94       400\n",
            "weighted avg       0.94      0.94      0.94       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91       105\n",
            "           1       0.71      0.74      0.72        91\n",
            "           2       0.64      0.68      0.66        92\n",
            "           3       0.85      0.84      0.85       112\n",
            "\n",
            "    accuracy                           0.79       400\n",
            "   macro avg       0.79      0.78      0.79       400\n",
            "weighted avg       0.80      0.79      0.79       400\n",
            "\n",
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       105\n",
            "           1       0.91      1.00      0.95        91\n",
            "           2       0.99      0.95      0.97        92\n",
            "           3       0.98      0.99      0.99       112\n",
            "\n",
            "    accuracy                           0.97       400\n",
            "   macro avg       0.97      0.97      0.97       400\n",
            "weighted avg       0.97      0.97      0.97       400\n",
            "\n",
            "SVM (rbf kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       105\n",
            "           1       0.95      0.99      0.97        91\n",
            "           2       0.94      0.95      0.94        92\n",
            "           3       0.98      0.95      0.96       112\n",
            "\n",
            "    accuracy                           0.96       400\n",
            "   macro avg       0.96      0.97      0.96       400\n",
            "weighted avg       0.97      0.96      0.97       400\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 3, 1, 1, 2, 0, 3, 1, 0, 0, 2, 3, 2, 2, 3, 3, 1, 0, 0, 1,\n",
              "       1, 2, 0, 1, 3, 2, 2, 0, 0, 0, 3, 0, 1, 1, 2, 0, 3, 0, 2, 3, 2, 0,\n",
              "       2, 2, 2, 1, 3, 1, 3, 1, 0, 0, 1, 1, 1, 3, 0, 0, 1, 3, 3, 1, 0, 0,\n",
              "       3, 3, 1, 2, 2, 2, 0, 1, 2, 0, 0, 3, 2, 2, 3, 2, 1, 0, 1, 3, 1, 3,\n",
              "       3, 0, 3, 3, 2, 1, 3, 2, 2, 3, 1, 1, 0, 0, 1, 0, 0, 3, 2, 0, 1, 1,\n",
              "       0, 0, 3, 1, 3, 2, 3, 2, 0, 2, 1, 3, 2, 1, 3, 3, 0, 3, 0, 2, 3, 0,\n",
              "       2, 2, 0, 3, 1, 0, 0, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 3, 1, 1, 0,\n",
              "       2, 2, 0, 1, 0, 2, 2, 3, 3, 2, 1, 0, 1, 2, 2, 3, 3, 0, 1, 0, 3, 1,\n",
              "       1, 2, 1, 0, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 0, 1, 3, 3, 1, 0, 1,\n",
              "       1, 1, 1, 2, 2, 3, 3, 3, 1, 2, 0, 0, 0, 2, 1, 1, 3, 1, 0, 2, 1, 1,\n",
              "       3, 2, 3, 0, 0, 2, 1, 3, 0, 1, 2, 0, 2, 3, 2, 0, 1, 3, 3, 0, 1, 3,\n",
              "       3, 3, 0, 3, 1, 2, 3, 3, 2, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 0, 1, 2,\n",
              "       2, 2, 3, 0, 2, 3, 2, 2, 2, 1, 0, 1, 0, 3, 3, 1, 3, 1, 0, 3, 1, 2,\n",
              "       0, 0, 3, 0, 1, 2, 3, 3, 3, 1, 1, 0, 1, 3, 3, 0, 1, 2, 2, 0, 3, 3,\n",
              "       2, 3, 2, 3, 2, 0, 2, 1, 1, 1, 0, 0, 0, 2, 2, 3, 1, 0, 1, 0, 1, 2,\n",
              "       3, 0, 3, 3, 2, 1, 3, 0, 0, 2, 1, 3, 2, 0, 1, 1, 1, 1, 1, 3, 2, 0,\n",
              "       0, 3, 3, 0, 3, 0, 0, 2, 0, 1, 2, 2, 2, 3, 0, 3, 2, 2, 3, 3, 3, 2,\n",
              "       1, 1, 0, 3, 1, 3, 3, 0, 2, 3, 2, 3, 3, 3, 0, 0, 2, 3, 0, 0, 2, 3,\n",
              "       2, 1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "mobile_train = pd.read_csv('data/mobile_train.csv')\n",
        "mobile_test = pd.read_csv('data/mobile_test.csv')\n",
        "\n",
        "X_train = mobile_train.drop('price_range', axis=1)\n",
        "y_train = mobile_train['price_range']\n",
        "X_test = mobile_test.drop('id', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "apply_decision_tree(X_train, X_test, y_train, y_test)\n",
        "apply_knn(X_train, X_test, y_train, y_test, n_neighbors=5)\n",
        "apply_logistic_regression(X_train, X_test, y_train, y_test)\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='linear')\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='rbf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY35jiORHPJh"
      },
      "source": [
        "#Task 4.2.\n",
        "Predict class label for test set using the best model found in task 4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_irQuKyHtdP",
        "outputId": "65172532-a7d4-4556-e5a4-958c2e7a072c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       105\n",
            "           1       0.91      1.00      0.95        91\n",
            "           2       0.99      0.95      0.97        92\n",
            "           3       0.98      0.99      0.99       112\n",
            "\n",
            "    accuracy                           0.97       400\n",
            "   macro avg       0.97      0.97      0.97       400\n",
            "weighted avg       0.97      0.97      0.97       400\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0, 2, 1, 3, 1, 1, 2, 0, 3, 1, 0, 1, 2, 3, 3, 2, 3, 3, 1, 0, 0, 2,\n",
              "       1, 2, 0, 1, 3, 2, 2, 0, 0, 0, 3, 0, 1, 1, 2, 0, 3, 0, 2, 3, 2, 0,\n",
              "       2, 3, 2, 1, 3, 1, 3, 1, 0, 0, 1, 1, 1, 3, 0, 0, 1, 3, 3, 1, 0, 0,\n",
              "       3, 3, 1, 2, 2, 2, 0, 1, 2, 0, 1, 3, 2, 2, 3, 2, 1, 0, 1, 3, 1, 3,\n",
              "       3, 0, 3, 3, 2, 1, 3, 2, 2, 3, 1, 1, 0, 0, 1, 0, 1, 3, 2, 0, 1, 1,\n",
              "       0, 0, 3, 1, 3, 2, 3, 2, 0, 2, 1, 3, 2, 1, 3, 3, 0, 2, 0, 2, 3, 0,\n",
              "       2, 2, 0, 3, 1, 0, 0, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 3, 1, 1, 0,\n",
              "       2, 2, 0, 1, 0, 2, 2, 3, 3, 3, 1, 0, 1, 2, 2, 3, 3, 0, 1, 0, 3, 1,\n",
              "       1, 2, 1, 0, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 0, 1, 3, 3, 1, 0, 1,\n",
              "       1, 1, 1, 2, 2, 3, 3, 3, 1, 2, 0, 0, 0, 2, 1, 1, 3, 1, 1, 2, 1, 1,\n",
              "       3, 2, 3, 0, 0, 2, 1, 3, 0, 1, 2, 0, 2, 3, 2, 0, 1, 3, 3, 0, 1, 3,\n",
              "       3, 3, 0, 3, 1, 2, 3, 3, 2, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 0, 1, 2,\n",
              "       2, 1, 3, 0, 2, 3, 2, 2, 2, 1, 0, 1, 0, 3, 3, 1, 3, 1, 1, 3, 1, 2,\n",
              "       0, 0, 3, 0, 1, 2, 3, 3, 3, 1, 1, 0, 1, 3, 3, 0, 1, 2, 2, 0, 3, 3,\n",
              "       2, 3, 2, 3, 2, 0, 2, 1, 1, 1, 0, 0, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2,\n",
              "       3, 0, 3, 3, 2, 1, 3, 0, 0, 2, 1, 3, 2, 0, 1, 1, 1, 1, 1, 3, 2, 0,\n",
              "       0, 3, 3, 0, 3, 0, 0, 2, 0, 1, 2, 2, 2, 3, 0, 3, 2, 3, 3, 3, 3, 2,\n",
              "       1, 1, 0, 3, 1, 3, 3, 0, 2, 3, 2, 3, 3, 3, 0, 0, 2, 3, 0, 0, 2, 3,\n",
              "       2, 1, 1, 2])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "apply_svm(X_train, X_test, y_train, y_test, kernel='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SCMLfMfyWPU"
      },
      "source": [
        "#Task 5.\n",
        "\n",
        "*   5.1.\tPerform SVM algorithm to **spambase dataset** using **linear kernel**.\n",
        "*   5.2.\tCompare the obtained results in task 5.1 with **SVM** using other kernels (**Polynomial Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: **accuracy, precision, recall, f1** measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU4u3CvDyfxg",
        "outputId": "c7d43e80-a88b-4800-cbb3-e56f5e2a8b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (linear kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       531\n",
            "           1       0.93      0.88      0.91       390\n",
            "\n",
            "    accuracy                           0.92       921\n",
            "   macro avg       0.92      0.92      0.92       921\n",
            "weighted avg       0.92      0.92      0.92       921\n",
            "\n",
            "SVM (poly kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.98      0.75       531\n",
            "           1       0.87      0.14      0.24       390\n",
            "\n",
            "    accuracy                           0.63       921\n",
            "   macro avg       0.74      0.56      0.49       921\n",
            "weighted avg       0.72      0.63      0.53       921\n",
            "\n",
            "SVM (sigmoid kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.71      0.69       531\n",
            "           1       0.57      0.54      0.56       390\n",
            "\n",
            "    accuracy                           0.64       921\n",
            "   macro avg       0.62      0.62      0.62       921\n",
            "weighted avg       0.63      0.64      0.63       921\n",
            "\n",
            "SVM (rbf kernel) Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.84      0.74       531\n",
            "           1       0.66      0.42      0.51       390\n",
            "\n",
            "    accuracy                           0.66       921\n",
            "   macro avg       0.66      0.63      0.63       921\n",
            "weighted avg       0.66      0.66      0.64       921\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(\"data/spambase.csv\", header=0)\n",
        "X = data.drop('class', axis=1).values\n",
        "y = data['class'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='linear')\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='poly')\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='sigmoid')\n",
        "apply_svm(X_train, X_test, y_train, y_test, kernel='rbf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}